{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fdcef5c",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "Goal: Compare runtimes of phylocomR array job on Hoffman2 over different iterations and tree sizes\n",
    "\n",
    "Workflow: \n",
    "\n",
    "1. Build R script for 1 iteration of phylocomR ph_comstruct function\n",
    "***\n",
    "2. Test an array job on Hoffman2 with 1000 iterations for a tree size of 100\n",
    "***\n",
    "3. Gather output files from test job and sort in python to determine min/max times and runtimes (TODO)\n",
    "***\n",
    "4. Make Iterative across multiple tree size/ iteration combinations (TODO) \n",
    "***\n",
    "5. Process all data and create graphs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d90a81",
   "metadata": {},
   "source": [
    " # Step 1: R script \n",
    "\n",
    "In order to utilize hoffman resources to run what is an otherwise very slow process, I built a small R script that runs one iteration of the ph_comstruct function from phylocomR. the output is a tibble containing all the output data from one iteration of the function. An additional file containing start and stop times is output. The code shown below can be found in the Bird repository in the single_array_run.R file.\n",
    "\n",
    "\n",
    "```R\n",
    "\n",
    "args = commandArgs(trailingOnly=TRUE) # accept the SGE_TASK_ID argument from hoffman2\n",
    "print(args) #prints the arguments which here should be equivalent to each SGE_TASK_ID\n",
    "n = as.integer(args[1])\n",
    "install.packages(\"phylocomr\")\n",
    "install.packages(\"ape\")\n",
    "install.packages(\"tictoc\")\n",
    "library(\"tictoc\")\n",
    "library(phylocomr)\n",
    "library(ape)\n",
    "\n",
    "\n",
    "start_time<-format(Sys.time(), \"%H:%M:%S\") #had to do this to only get the time. \n",
    "sample_tree_cluster<-read.tree(file = \"sample_tree_for_cluster.tre\")\n",
    "\n",
    "full_tree_cluster<-read.tree(file = \"full_tree_for_cluster.tre\")\n",
    "\n",
    "df_touse_cluster<-data.frame(sample = \"species\", occurrence = 1, names = sample_tree_cluster$tip.label)\n",
    "res_sample_cluster<- ph_comstruct(sample = df_touse_cluster, phylo = full_tree_cluster, randomizations = 1)\n",
    "typeof(res_sample_cluster)\n",
    "#write.table(res_sample_cluster, file = \"sample_phcomstruct_output\") #better to have csv maybe, easier to manipulate?\n",
    "write.csv(res_sample_cluster, file = paste(\"sample_phcomstruct_output.csv\", n)) #this i believe is the output file. I think it's maybe better than table?\n",
    "end_time<-format(Sys.time(), \"%H:%M:%S\")\n",
    "\n",
    "write.table(c(start_time, end_time), file = \"table_attempt.txt\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1771dd2",
   "metadata": {},
   "source": [
    "# Step 2: Single array job\n",
    "\n",
    "In order to run 1000 randomizations of the above code to achieve a distribution of expected randomized pd values (for later statistical use), I used qsub to run the above R script 1000 times on Hoffman2. Code for this submission script (as seen below) can be found in submit_array_job.sh\n",
    "\n",
    "\n",
    "```Bash \n",
    "\n",
    "#!/bin/bash\n",
    "#$ -cwd #uses current working directory\n",
    "# error = Merged with joblog\n",
    "#$ -o /u/home/m/mchari/joblog_$JOB_ID/joblog.$JOB_ID.$TASK_ID #creates a file called joblog.jobidnumber.taskidnumber to write to. \n",
    "#$ -j y \n",
    "#$ -l h_rt=0:30:00,h_data=2G #requests 30 minutes, 2GB of data (per core)\n",
    "#$ -pe shared 2 #requests 2 cores\n",
    "# Email address to notify\n",
    "#$ -M $USER@mail #don't change this line, finds your email in the system \n",
    "# Notify when\n",
    "##$ -m bea #sends you an email (b) when the job begins (e) when job ends (a) when job is aborted (error)\n",
    "#$ -t 1-5:1 # 1 to 10, with step size of 1\n",
    "\n",
    "# load the job environment:\n",
    ". /u/local/Modules/default/init/modules.sh\n",
    "module load R\n",
    "\n",
    "echo ${SGE_TASK_ID}\n",
    "\n",
    "# run julia code\n",
    "echo Running phylo_code for n = ${SGE_TASK_ID} #prints this quote to joblog.jobidnumber\n",
    "Rscript single_array_run.R ${SGE_TASK_ID}  > /u/home/m/mchari/joblog_$JOB_ID/output.$JOB_ID.${SGE_TASK_ID}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233634dd",
   "metadata": {},
   "source": [
    "# Step 3: Processing single array job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff10c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
